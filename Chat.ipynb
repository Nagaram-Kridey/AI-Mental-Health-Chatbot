{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b8f3c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\anaconda\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: nltk in d:\\anaconda\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: openpyxl in d:\\anaconda\\lib\\site-packages (3.0.10)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in d:\\anaconda\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: et_xmlfile in d:\\anaconda\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in d:\\anaconda\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in d:\\anaconda\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in d:\\anaconda\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\anaconda\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\anaconda\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\anaconda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow numpy pandas nltk openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6a5590",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nkrid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "\n",
    "# Download necessary NLP resources\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9aa4699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>User Input</th>\n",
       "      <th>Bot Response</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I feel really down today.</td>\n",
       "      <td>I'm sorry to hear that. Do you want to talk ab...</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I had a panic attack.</td>\n",
       "      <td>That sounds tough. Try to take deep breaths. I...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Panic Attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I'm so stressed with work.</td>\n",
       "      <td>That sounds overwhelming. Would you like to tr...</td>\n",
       "      <td>Stress</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Work Stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I can't sleep at night.</td>\n",
       "      <td>I'm here to help. Have you tried deep breathin...</td>\n",
       "      <td>Insomnia</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Sleep Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I'm feeling better today!</td>\n",
       "      <td>That's great! What helped you feel better?</td>\n",
       "      <td>Happiness</td>\n",
       "      <td>Positive</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                  User Input  \\\n",
       "0   1   I feel really down today.   \n",
       "1   2       I had a panic attack.   \n",
       "2   3  I'm so stressed with work.   \n",
       "3   4     I can't sleep at night.   \n",
       "4   5   I'm feeling better today!   \n",
       "\n",
       "                                        Bot Response     Intent Sentiment  \\\n",
       "0  I'm sorry to hear that. Do you want to talk ab...    Sadness  Negative   \n",
       "1  That sounds tough. Try to take deep breaths. I...    Anxiety  Negative   \n",
       "2  That sounds overwhelming. Would you like to tr...     Stress  Negative   \n",
       "3  I'm here to help. Have you tried deep breathin...   Insomnia  Negative   \n",
       "4         That's great! What helped you feel better?  Happiness  Positive   \n",
       "\n",
       "        Context  \n",
       "0    Depression  \n",
       "1  Panic Attack  \n",
       "2   Work Stress  \n",
       "3  Sleep Issues  \n",
       "4       General  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (Ensure the file is in the same directory as your notebook)\n",
    "file_path = \"mental_health_chatbot_dataset.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Show dataset preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be046867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>User Input</th>\n",
       "      <th>Bot Response</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>i feel really down today</td>\n",
       "      <td>im sorry to hear that do you want to talk abou...</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>i had a panic attack</td>\n",
       "      <td>that sounds tough try to take deep breaths im ...</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Panic Attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>im so stressed with work</td>\n",
       "      <td>that sounds overwhelming would you like to try...</td>\n",
       "      <td>Stress</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Work Stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>i cant sleep at night</td>\n",
       "      <td>im here to help have you tried deep breathing ...</td>\n",
       "      <td>Insomnia</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Sleep Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>im feeling better today</td>\n",
       "      <td>thats great what helped you feel better</td>\n",
       "      <td>Happiness</td>\n",
       "      <td>Positive</td>\n",
       "      <td>General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                User Input  \\\n",
       "0   1  i feel really down today   \n",
       "1   2      i had a panic attack   \n",
       "2   3  im so stressed with work   \n",
       "3   4     i cant sleep at night   \n",
       "4   5   im feeling better today   \n",
       "\n",
       "                                        Bot Response     Intent Sentiment  \\\n",
       "0  im sorry to hear that do you want to talk abou...    Sadness  Negative   \n",
       "1  that sounds tough try to take deep breaths im ...    Anxiety  Negative   \n",
       "2  that sounds overwhelming would you like to try...     Stress  Negative   \n",
       "3  im here to help have you tried deep breathing ...   Insomnia  Negative   \n",
       "4            thats great what helped you feel better  Happiness  Positive   \n",
       "\n",
       "        Context  \n",
       "0    Depression  \n",
       "1  Panic Attack  \n",
       "2   Work Stress  \n",
       "3  Sleep Issues  \n",
       "4       General  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to clean text\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()  # Convert to lowercase\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)  # Remove punctuation\n",
    "    text = nltk.word_tokenize(text)  # Tokenize\n",
    "    return \" \".join(text)\n",
    "\n",
    "# Apply preprocessing to user inputs and bot responses\n",
    "df[\"User Input\"] = df[\"User Input\"].apply(preprocess_text)\n",
    "df[\"Bot Response\"] = df[\"Bot Response\"].apply(preprocess_text)\n",
    "\n",
    "# Display cleaned data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf5cf129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 20), (30, 20))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define hyperparameters\n",
    "MAX_LEN = 20  # Maximum sequence length\n",
    "VOCAB_SIZE = 10000  # Limit vocabulary size\n",
    "\n",
    "# Create a tokenizer\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, filters=\"\")\n",
    "tokenizer.fit_on_texts(df[\"User Input\"].tolist() + df[\"Bot Response\"].tolist())\n",
    "\n",
    "# Convert text to sequences\n",
    "input_sequences = tokenizer.texts_to_sequences(df[\"User Input\"])\n",
    "response_sequences = tokenizer.texts_to_sequences(df[\"Bot Response\"])\n",
    "\n",
    "# Apply padding\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=MAX_LEN, padding=\"post\")\n",
    "response_sequences = pad_sequences(response_sequences, maxlen=MAX_LEN, padding=\"post\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "input_sequences = np.array(input_sequences)\n",
    "response_sequences = np.array(response_sequences)\n",
    "\n",
    "# Check shapes\n",
    "input_sequences.shape, response_sequences.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "832e27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save tokenizer to a file\n",
    "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab2c70da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570,000</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,280,000\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,280,000\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m394,240\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m), │    \u001b[38;5;34m394,240\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m10000\u001b[0m) │  \u001b[38;5;34m2,570,000\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,918,480</span> (22.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,918,480\u001b[0m (22.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,918,480</span> (22.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,918,480\u001b[0m (22.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define encoder\n",
    "encoder_inputs = Input(shape=(MAX_LEN,))\n",
    "encoder_embedding = Embedding(VOCAB_SIZE, 128)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "\n",
    "# Define decoder\n",
    "decoder_inputs = Input(shape=(MAX_LEN,))\n",
    "decoder_embedding = Embedding(VOCAB_SIZE, 128)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
    "\n",
    "# Dense output layer\n",
    "decoder_dense = Dense(VOCAB_SIZE, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Build and compile model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "# Show model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "005b9943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - loss: 9.2111 - val_loss: 9.2005\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 9.1990 - val_loss: 9.1879\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 9.1844 - val_loss: 9.1684\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - loss: 9.1618 - val_loss: 9.1331\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 9.1203 - val_loss: 9.0580\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 9.0323 - val_loss: 8.8757\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 8.8248 - val_loss: 8.5070\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 8.4197 - val_loss: 8.0878\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - loss: 7.9429 - val_loss: 7.7224\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 7.5050 - val_loss: 7.3745\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - loss: 7.0831 - val_loss: 7.0165\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - loss: 6.6482 - val_loss: 6.6416\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - loss: 6.1900 - val_loss: 6.2567\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - loss: 5.7131 - val_loss: 5.8815\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - loss: 5.2364 - val_loss: 5.5449\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 4.7900 - val_loss: 5.2717\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - loss: 4.4025 - val_loss: 5.0651\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - loss: 4.0825 - val_loss: 4.9131\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 3.8231 - val_loss: 4.8025\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - loss: 3.6137 - val_loss: 4.7238\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - loss: 3.4446 - val_loss: 4.6708\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - loss: 3.3101 - val_loss: 4.6397\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - loss: 3.2068 - val_loss: 4.6285\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - loss: 3.1322 - val_loss: 4.6336\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - loss: 3.0808 - val_loss: 4.6507\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 3.0459 - val_loss: 4.6769\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - loss: 3.0230 - val_loss: 4.7092\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - loss: 3.0081 - val_loss: 4.7417\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - loss: 2.9965 - val_loss: 4.7715\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - loss: 2.9841 - val_loss: 4.7961\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - loss: 2.9695 - val_loss: 4.8114\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 2.9523 - val_loss: 4.8193\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 2.9322 - val_loss: 4.8239\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - loss: 2.9105 - val_loss: 4.8262\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - loss: 2.8876 - val_loss: 4.8269\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - loss: 2.8654 - val_loss: 4.8300\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - loss: 2.8455 - val_loss: 4.8329\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - loss: 2.8274 - val_loss: 4.8327\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - loss: 2.8108 - val_loss: 4.8341\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 2.7960 - val_loss: 4.8382\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - loss: 2.7827 - val_loss: 4.8447\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 2.7711 - val_loss: 4.8528\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - loss: 2.7608 - val_loss: 4.8613\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - loss: 2.7510 - val_loss: 4.8704\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 2.7406 - val_loss: 4.8791\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - loss: 2.7294 - val_loss: 4.8866\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - loss: 2.7175 - val_loss: 4.8933\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - loss: 2.7060 - val_loss: 4.8992\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - loss: 2.6945 - val_loss: 4.9044\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - loss: 2.6829 - val_loss: 4.9091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24a47463590>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit([input_sequences, response_sequences], response_sequences, batch_size=64, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dfcce52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h5py is installed. Version: 3.13.0\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "print(\"h5py is installed. Version:\", h5py.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb915b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Successfully Saved!!\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mental_health_chatbot.keras\")\n",
    "print(\"Model Successfully Saved!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b0a76c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained chatbot model\n",
    "model = load_model(\"mental_health_chatbot.keras\")\n",
    "\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3379c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66f2f76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "You: Hello\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step\n",
      "Chatbot: im\n",
      "20\n",
      "You: How are you?\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Chatbot: im\n",
      "20\n",
      "You: Blah Blah\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Chatbot: im\n",
      "20\n",
      "You: exit\n",
      "Chatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load tokenizer\n",
    "with open(\"tokenizer.pkl\", \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Load trained model\n",
    "model = load_model(\"mental_health_chatbot.keras\")\n",
    "\n",
    "# Define function to generate chatbot responses\n",
    "def get_bot_response(user_input):\n",
    "    user_seq = tokenizer.texts_to_sequences([user_input])\n",
    "    user_seq = pad_sequences(user_seq, maxlen=MAX_LEN, padding=\"post\")  # Ensure consistent length\n",
    "\n",
    "    # Pass user input through the model\n",
    "    prediction = model.predict([user_seq, np.zeros((1, MAX_LEN))])  # Ensure decoder input is correct\n",
    "    predicted_index = np.argmax(prediction, axis=-1)\n",
    "\n",
    "    # Convert predicted sequence back to words\n",
    "    response_words = [word for word, index in tokenizer.word_index.items() if index in predicted_index[0]]\n",
    "\n",
    "    return \" \".join(response_words)\n",
    "\n",
    "\n",
    "# Run chatbot loop\n",
    "while True:\n",
    "    print(MAX_LEN)\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    response = get_bot_response(user_input)\n",
    "    print(\"Chatbot:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0a10757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'you': 1, 'i': 2, 'to': 3, 'im': 4, 'can': 5, 'feel': 6, 'help': 7, 'that': 8, '’': 9, 'what': 10, 'is': 11, 'a': 12, 'be': 13, 'have': 14, 'here': 15, 'about': 16, 'tried': 17, 's': 18, 'with': 19, 'feeling': 20, 'like': 21, 'want': 22, 'how': 23, 'and': 24, 'really': 25, 'so': 26, 'some': 27, 'do': 28, 'for': 29, 'would': 30, 'today': 31, 'day': 32, 'emotions': 33, 'the': 34, 'listen': 35, 'alone': 36, 'life': 37, 'sorry': 38, 'sounds': 39, 'tough': 40, 'try': 41, 'deep': 42, 'relaxation': 43, 'techniques': 44, 'breathing': 45, 'or': 46, 'way': 47, 'talking': 48, 'exercises': 49, 'on': 50, 'one': 51, 'step': 52, 'might': 53, 'had': 54, 'attack': 55, 'better': 56, 'think': 57, 'me': 58, 'having': 59, 'need': 60, 'managing': 61, 'my': 62, 'just': 63, 'someone': 64, 'overthinking': 65, 'deal': 66, 'stress': 67, 'selfesteem': 68, 'professional': 69, 'responsibilities': 70, 'negative': 71, 'thoughts': 72, 'an': 73, 'bad': 74, 'dreams': 75, 'stuck': 76, 'in': 77, 'build': 78, 'confidence': 79, 'event': 80, 'expressing': 81, 'talk': 82, 'overwhelming': 83, 'before': 84, 'bed': 85, 'thats': 86, 'great': 87, 'are': 88, 'not': 89, 'your': 90, 'youre': 91, 'important': 92, 'support': 93, 'of': 94, 'friend': 95, 'share': 96, 'takes': 97, 'time': 98, 'thing': 99, 'small': 100, 'hard': 101, 'something': 102, 'down': 103, 'panic': 104, 'stressed': 105, 'work': 106, 'cant': 107, 'sleep': 108, 'at': 109, 'night': 110, 'don': 111, 't': 112, 'anyone': 113, 'cares': 114, 'good': 115, 'giving': 116, 'up': 117, 'suggest': 118, 'coping': 119, 'strategies': 120, 'anxious': 121, 'future': 122, 'rough': 123, 'nobody': 124, 'understands': 125, 'constantly': 126, 'struggling': 127, 'overwhelmed': 128, 'stop': 129, 'feels': 130, 'meaningless': 131, 'sometimes': 132, 'when': 133, 'hopeless': 134, 'calm': 135, 'myself': 136, 'during': 137, 'anxiety': 138, 'keep': 139, 'happy': 140, 'scared': 141, 'upcoming': 142, 'trouble': 143, 'hear': 144, 'it': 145, 'take': 146, 'breaths': 147, 'meditation': 148, 'helped': 149, 'wonderful': 150, 'made': 151, 'this': 152, 'course': 153, 'journaling': 154, 'completely': 155, 'okay': 156, 'bothering': 157, 'its': 158, 'understandable': 159, 'grounding': 160, 'difficult': 161, 'if': 162, 'unheard': 163, 'listening': 164, 'whatever': 165, 'mind': 166, 'exhausting': 167, 'mindfulness': 168, 'loneliness': 169, 'painful': 170, 'appreciate': 171, 'yourself': 172, 'seeking': 173, 'brave': 174, 'guidance': 175, 'find': 176, 'breaking': 177, 'them': 178, 'into': 179, 'steps': 180, 'persistent': 181, 'thoughtchallenging': 182, 'has': 183, 'meaning': 184, 'even': 185, 'times': 186, 'brings': 187, 'joy': 188, 'hopelessness': 189, 'slowly': 190, 'focusing': 191, 'present': 192, 'unsettling': 193, 'frustrating': 194, 'whats': 195, 'change': 196, 'make': 197, 'happiness': 198, 'journey': 199, 'makes': 200, 'smile': 201, 're': 202, 'proud': 203, 'fear': 204, 'natural': 205, 'preparing': 206, 'by': 207, 'writing': 208}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c37d607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Input Sequence: [[  2   6  25 103  31   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2  54  12 104  55   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4  26 105  19 106   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2 107 108 109 110   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4  20  56  31   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]]\n",
      "Sample Response Sequence: [[  4  38   3 144   8  28   1  22   3  82  16 145   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  8  39  40  41   3 146  42 147   4  15  29   1   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  8  39  83  30   1  21   3  41  27  43  44   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4  15   3   7  14   1  17  42  45  46 148  84  85   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 86  87  10 149   1   6  56   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample Input Sequence:\", input_sequences[:5])\n",
    "print(\"Sample Response Sequence:\", response_sequences[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e98d8b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['im sorry to hear that do you want to talk about it', 'that sounds tough try to take deep breaths im here for you', 'that sounds overwhelming would you like to try some relaxation techniques', 'im here to help have you tried deep breathing or meditation before bed', 'thats great what helped you feel better']\n"
     ]
    }
   ],
   "source": [
    "decoded_responses = tokenizer.sequences_to_texts(response_sequences[:5])\n",
    "print(decoded_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91c9c946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor shape=(None, 20), dtype=float32, sparse=False, name=input_layer_2>,\n",
       " <KerasTensor shape=(None, 20), dtype=float32, sparse=False, name=input_layer_3>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input  # Check input structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f50b8f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "[[[1.1284223e-02 1.8427793e-02 9.9566299e-04 ... 1.2550480e-06\n",
      "   1.5250345e-06 1.4948503e-06]\n",
      "  [1.9975832e-02 2.4150236e-02 1.1443802e-03 ... 1.0105922e-06\n",
      "   1.2932737e-06 1.2431459e-06]\n",
      "  [3.3729289e-02 2.9346872e-02 1.2542300e-03 ... 9.6087342e-07\n",
      "   1.2864533e-06 1.2182938e-06]\n",
      "  ...\n",
      "  [8.0921674e-01 1.8271808e-02 2.1336253e-03 ... 8.5411024e-08\n",
      "   8.4877378e-08 8.1688540e-08]\n",
      "  [8.0923754e-01 1.8270062e-02 2.1333850e-03 ... 8.5404579e-08\n",
      "   8.4872759e-08 8.1683474e-08]\n",
      "  [8.0924505e-01 1.8269371e-02 2.1332931e-03 ... 8.5403094e-08\n",
      "   8.4871928e-08 8.1682366e-08]]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = np.zeros((1, MAX_LEN))  # Example decoder input (modify if needed)\n",
    "\n",
    "predicted_sequence = model.predict([input_sequences[:1], decoder_input])\n",
    "print(predicted_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c0401d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tokens = np.argmax(predicted_sequence, axis=-1)  # Get highest probability token indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c224107",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Response: im im im\n"
     ]
    }
   ],
   "source": [
    "predicted_text = tokenizer.sequences_to_texts(predicted_tokens)\n",
    "print(\"Predicted Response:\", predicted_text[0])  # Extract first response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9edf85d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved Response: have loneliness overwhelming what so on im im you\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sample_with_temperature(predictions, temperature=0.7):\n",
    "    predictions = np.log(predictions + 1e-9) / temperature\n",
    "    exp_preds = np.exp(predictions)\n",
    "    probabilities = exp_preds / np.sum(exp_preds)\n",
    "    return np.random.choice(len(probabilities), p=probabilities)\n",
    "\n",
    "predicted_tokens = [sample_with_temperature(pred, temperature=0.8) for pred in predicted_sequence[0]]\n",
    "predicted_text = tokenizer.sequences_to_texts([predicted_tokens])\n",
    "\n",
    "print(\"Improved Response:\", predicted_text[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e85575d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step\n"
     ]
    }
   ],
   "source": [
    "start_token = tokenizer.word_index.get(\"start\", 1)  # Use \"start\" token if available\n",
    "decoder_input = np.array([[start_token] + [0] * (MAX_LEN - 1)])  # Pad to max length\n",
    "\n",
    "predicted_sequence = model.predict([input_sequences[:1], decoder_input])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d917a9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter(\" \".join(df[\"Bot Response\"]).split())\n",
    "print(word_counts[\"im\"])  # See how often \"im\" appears\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a4a0395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Response: im im im\n"
     ]
    }
   ],
   "source": [
    "predicted_tokens = np.argmax(predicted_sequence, axis=-1)\n",
    "predicted_text = tokenizer.sequences_to_texts(predicted_tokens)\n",
    "print(\"Fixed Response:\", predicted_text[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55709c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
